\section{Related Work}
\label{sec:related}
\subsection{JIT Defect Prediction}
Some previous studies focus on change-level defect prediction (i.e., JIT defect prediction). For example, Mockus and Weiss~\cite{Mockus2000} predict commits as being buggy or not in an industrial project. They use metric-based features, such as the number of subsystems touched, the number of files modified, the number of lines of added code, and the number of modification requests. Motivated by their previous work, Kamei et al.~\cite{Kamei:2013:LES} built upon the set of code change features, reporting that the addition of a variety of features that were extracted from the Version Control System (VCS) and the Issue Tracking System (ITS) helped to improve the prediction accuracy. They conduct an empirical study of the effectiveness of JIT defect prediction on a set of six open source and five commercial projects and also evaluate their findings when considering the effort required to review the changes.

Aversano \emph{et al.}~\cite{Aversano2007} and Kim \emph{et al.}~\cite{Kim2008} use source code change logs to predict commits as being buggy or not. For example, Kim \emph{et al.}~\cite{Kim2008} used the identifiers in added and deleted source code and the words in change logs. The experimental results on the datasets collected from 12 open source software projects show that the proposed approach achieve 78 percent accuracy and a 60 percent recall.

Kononenko et al.~\cite{Kononenko:2015} find that the addition of code change features that were extracted from code review databases contributed a significant amount of explanatory power to JIT models. McIntosh and Kamei also use 5 families of code and review features in the context of JIT defect prediction. Through a case study of 37,524 changes from QT and OpenStack systems, the paper show that the importance of impactful families of code change features like Size and Review are consistently under/overestimated in the studied systems.

Comparing with these previous studies, we introduce the JIT defect prediction model (DeepJIT) that learns a deep representation of commits. We also evaluate the prediction performance of DeepJIT comparing with other JIT models on the dataset including code change properties. We extended the datasets that McIntosh and Kamei used to analyze~\footnote{\url{https://github.com/software-rebels/JITMovingTarget}} by adding commit messages and code changes. 

% Yasu says: this subsection was done. 

\cmt{Yasu says: this paper may be related as well. Fine-Grained Just-In-Time Defect Prediction Luca Pascarella, Fabio Palomba, Alberto Bacchelli}

\subsection{Deep Learning Models in Defect Prediction}

Deep learning has recently attracted increasing interests in software defect prediction. Deep Belief Network (DBN) \cite{DBN-Hinton06} has been commonly used in previous work. For example,  a recent work \cite{Yang:2015:DLJ}  used the Deep Belief Network to build JIT defect prediction models. Their approach still however rely on the same set of metric-based features that are manually engineered as in earlier work. Other studies (e.g., \cite{Yang:2015:DLJ,Wang:2016:ALS,WangTSE2018}) also used Deep Belief Network to automatically learn features for defect prediction. Unlike our approach, their models are not end-to-end trainable, i.e., features are learned separately (not using the defect ground-truths) and are then input to a separate traditional classifier. This approach has also been used in previous work (e.g. \cite{Li2017,HoaTSE2019}) where two other well-known deep learning architectures (Long Short Term Memory in \cite{HoaTSE2019}  and Convolutional Neural Network in \cite{Li2017}) was leveraged to automatic feature learning for defect prediction. There is a risk in those approaches that the learned features may not correlate with defect outcomes. End-to-end models like our approach address this issue by enforcing the models to learn and generate features that best correlate with the target label.


% Yasu says: Hi Hoa, I listed three papers that should be discussed in this subsection.

% Xin Xia's group
% 1. QRS https://dl.acm.org/citation.cfm?id=2866837

% Lin Tang's group
% 1. TSE Deep Semantic Feature Learning for Software Defect Prediction. Song Wang, Taiyue Liu, Jaechang Nam, and Lin Tan.
% 2. ICSE Automatically Learning Semantic Features for Defect Prediction. Song Wang, Taiyue Liu, and Lin Tan. In the proceedings of the International Conference on Software Engineering. Acceptance Rate: 19% (101/530)

%Say the difference between them and us.